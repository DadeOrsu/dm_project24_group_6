{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "This notebook uses DBSCAN as a clustering density based approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before starting, for reasons of time we could,for this delivery, do the clustering on the full dataset so for now we decided to employ some sort of data reduction as to make it feasible to run such an algorithm\n",
    "\n",
    "The approach we used was:\n",
    "- aggregation of races features for each races instance (the year races couple in the dataset)\n",
    "- remove useless features that don't mean anything after aggregation e.g. stages\n",
    "- chunking on the dataset reduction every two years to get small enough clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.cluster import DBSCAN\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def most_frequent(series):\n",
    "    return series.mode()[0] if not series.mode().empty else series.iloc[0]\n",
    "RACES_PATH=path.join(\"..\",\"dataset\",\"engineered_races.csv\")\n",
    "races_df=pd.read_csv(RACES_PATH)\n",
    "\n",
    "#aggregation of races to reduce dataset size\n",
    "clustering_data=races_df.groupby(['date','stage','std_name','cyclist']).agg({\n",
    "    'profile':most_frequent,\n",
    "    'is_tarmac':most_frequent,\n",
    "    'difficulty_level':most_frequent,\n",
    "\n",
    "    'points':'sum',\n",
    "\n",
    "    'length':'mean',\n",
    "    'climb_total':'mean',\n",
    "    'competitive_age':'mean',\n",
    "    'startlist_quality':'mean',\n",
    "    'delta':'mean',\n",
    "    'performance_index':'mean',\n",
    "    'difficulty':'mean',\n",
    "    'convenience_score':'mean',\n",
    "    'difficulty_score':'mean',\n",
    "    'gain_ratio':'mean',\n",
    "\n",
    "    'cyclist_age':'first',\n",
    "    'position':'first',\n",
    "    'cyclist_team':'first',\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "#convert to timestamp(units are useless since it's getting normalized)\n",
    "clustering_data['date']=pd.to_datetime(clustering_data['date'])\n",
    "clustering_data['day']=clustering_data['date'].dt.day\n",
    "clustering_data['month']=clustering_data['date'].dt.month\n",
    "clustering_data['year']=clustering_data['date'].dt.year\n",
    "\n",
    "#one hot encoding difficulty\n",
    "ohe_diff_lvl=pd.get_dummies(races_df['difficulty_level']).astype(float)\n",
    "\n",
    "#dividing into chunks\n",
    "dec_cut=pd.date_range(\n",
    "    start=clustering_data['date'].min(),\n",
    "    end=clustering_data['date'].max(),\n",
    "    freq='2YE'\n",
    ")\n",
    "#apply chunks\n",
    "clustering_data['decade']=pd.cut(\n",
    "    clustering_data['date'],\n",
    "    bins=dec_cut,\n",
    ")\n",
    "clustering_data[ohe_diff_lvl.columns]=ohe_diff_lvl\n",
    "#remove useless columns\n",
    "clustering_data=clustering_data.drop(columns=\"date\")\n",
    "\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering organization\n",
    "\n",
    "A few notes are due before starting, first the eps are difficulty to setup for now a good strategy would be to take inspiration using the first paper the introduced the algorithm, which you can find [here](https://dl.acm.org/doi/10.5555/3001460.3001507), and use the distance from the k-th NN varying K until we find a good eps value for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying the elbow method\n",
    "In this part since it is diifcult to estimate values we picked a kth neighbor that is not too low to have an eps taht is higher and manages to reach more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import utils\n",
    "clustering_data=clustering_data.drop(columns=[\"difficulty_level\",\"stage\",\"std_name\",\"cyclist\",\"cyclist_team\",\"easy\",\"hard\",\"moderate\",\"is_tarmac\",\"gain_ratio\",\"difficulty_score\",\"position\"]).drop_duplicates()\n",
    "\n",
    "std_scaler=StandardScaler()\n",
    "\n",
    "print(clustering_data.columns)\n",
    "\n",
    "dec_groups=clustering_data.groupby('decade')\n",
    "normalized_decade_groups={k:std_scaler.fit_transform(g.drop(columns=\"decade\").drop_duplicates()) for k,g in dec_groups }\n",
    "\n",
    "print({k:len(g) for k,g in normalized_decade_groups.items()})\n",
    "\n",
    "initial_eps=dict()\n",
    "\n",
    "kth_neighbor=30\n",
    "\n",
    "for k,data in normalized_decade_groups.items():\n",
    "    min_pts=data.shape[1]\n",
    "    nn=NearestNeighbors(n_neighbors=min_pts-1,n_jobs=-1)\n",
    "    nn.fit(data)\n",
    "    distances,indices= nn.kneighbors(data)\n",
    "    k_distances= np.sort(distances[:, -1])\n",
    "\n",
    "    initial_eps[k]=k_distances[kth_neighbor-1]\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "number of groups={len(normalized_decade_groups)}\n",
    "initial eps values per group={initial_eps}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the sorted distances we can pick the eps values and proceed to test dbscan , in this case we have more starting eps values given the segmentation hance we have a lot of tests to do.\n",
    "\n",
    "\n",
    "NOTE: since we didn't manage to make execution feasible we had to cut the clusterings and we go only from 1970 to 1994 with jumps of two years\n",
    "\n",
    "NOTE: DBSCAN relies a lot on the density we where afraid that sampling would make clustering meaningless because of too many points removed and having a too approximated distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful for reference\n",
    "db_scan_mapping={\n",
    "    -1:'noisy',\n",
    "    0:'border',\n",
    "    1:'core'\n",
    "\n",
    "}\n",
    "\n",
    "group_results=pd.DataFrame()\n",
    "\n",
    "\n",
    "for k,decade_data in normalized_decade_groups.items():\n",
    "    #NOTE: this might have to be revisited for it's just to try if everyting works\n",
    "    dimension=decade_data.shape[0]\n",
    "    min_pts=int(dimension-1)\n",
    "    #using the method seen at laboratory to select initial values\n",
    "    #print(decade_data.drop(columns=\"decade\").info())\n",
    "    maximum_distance = abs(decade_data.max() - decade_data.min()).sum().item()\n",
    "    average_concentration = dimension / maximum_distance\n",
    "    #use diferent scales for eps values\n",
    "    # during the tests a lot of low values where not taken into consideration\n",
    "    eps_values=initial_eps[k] * np.array([500,250,100,50,10, 5, 2.5, 1, 0.1, 0.01, 0.0001])\n",
    "    #try various metrics\n",
    "    metrics=['euclidean']\n",
    "\n",
    "    min_pts_values=[min_pts]\n",
    "    print(\n",
    "    f\"\"\"\n",
    "    period {k}\n",
    "    maxium distance: {maximum_distance}\n",
    "    average concentration:{average_concentration}\n",
    "    eps values:{eps_values}\n",
    "    used metrics:{metrics}\n",
    "    number of minimum samples:{min_pts}\n",
    "    number of samples used:{decade_data.shape[0]}\n",
    "    \"\"\"\n",
    "    )\n",
    "    #normalization is done for each group\n",
    "    result=utils.run_dbscan(min_pts_values,eps_values,metrics,decade_data)\n",
    "    result[\"group\"]=k\n",
    "    group_results=pd.concat([group_results,result])\n",
    "group_results.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the result we only managed to find a meaningful clustering in th first two years with a silhoutte score of 0.79 all the otehr are all noise , however after some consideration we found out that we don't have any meaningful clusteriong because we have all points taht are core so eps is too high bnut lowering it doesn't change even after testing very different scales both big and small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx=0\n",
    "best_params=group_results.iloc[best_idx]\n",
    "\n",
    "best_dbscan=DBSCAN(eps=best_params['eps'],min_samples=best_params['min_samples']).fit(normalized_decade_groups[best_params['group']])\n",
    "\n",
    "labels=best_dbscan.labels_\n",
    "\n",
    "statistics=np.unique(best_dbscan.labels_,return_counts=True)\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "results:{best_params}\n",
    "statistics:\n",
    "    raw counts: noise {statistics[0][0]}| core {statistics[1][0]}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for this first delivery we can only say taht after some consideration the dataset tends to be very sparse, probably some sensd approaches would be to:\n",
    "- use sampling and make a bigger hyperparameters space.\n",
    "- find a more refined method to select the eps values.\n",
    "- use different segmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see clustyring by years even after trying to reduce the dimension to get less sparse clusters is not effective, aside from a nice 0.71 in the first part we cannot get much more than that, we can infer very different densities across years which makes for very bad clusterings.\n",
    "\n",
    "So we can try other kind of segmentations, a first approach could be geospatial: group by the race occurencies across time.\n",
    "\n",
    "## geospatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stage</th>\n",
       "      <th>cyclist</th>\n",
       "      <th>profile</th>\n",
       "      <th>is_tarmac</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>points</th>\n",
       "      <th>length</th>\n",
       "      <th>climb_total</th>\n",
       "      <th>competitive_age</th>\n",
       "      <th>startlist_quality</th>\n",
       "      <th>delta</th>\n",
       "      <th>performance_index</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>convenience_score</th>\n",
       "      <th>difficulty_score</th>\n",
       "      <th>gain_ratio</th>\n",
       "      <th>cyclist_age</th>\n",
       "      <th>position</th>\n",
       "      <th>cyclist_team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amstel-gold-race</th>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "      <td>4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dauphine</th>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "      <td>26669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwars-door-vlaanderen</th>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "      <td>2656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3-harelbeke</th>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>giro-d-italia</th>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "      <td>95581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp-montreal</th>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp-quebec</th>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gran-camino</th>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il-lombardia</th>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itzulia-basque-country</th>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "      <td>17936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la-fleche-wallone</th>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liege-bastogne-liege</th>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milano-sanremo</th>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "      <td>6454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omloop-het-nieuwsblad</th>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "      <td>4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris-nice</th>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "      <td>32362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris-roubaix</th>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "      <td>3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ronde-van-vlaanderen</th>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "      <td>4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san-sebastian</th>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strade-bianche</th>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tirreno-adriatico</th>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "      <td>27622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour-de-france</th>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "      <td>145483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour-de-romandie</th>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "      <td>20294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tour-de-suisse</th>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "      <td>33679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uae-tour</th>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volta-a-catalunya</th>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "      <td>26022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuelta-a-espana</th>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "      <td>105382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world-championship</th>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "      <td>3917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date   stage  cyclist  profile  is_tarmac  \\\n",
       "std_name                                                              \n",
       "amstel-gold-race          4349    4349     4349     4349       4349   \n",
       "dauphine                 26669   26669    26669    26669      26669   \n",
       "dwars-door-vlaanderen     2656    2656     2656     2656       2656   \n",
       "e3-harelbeke              3287    3287     3287     3287       3287   \n",
       "giro-d-italia            95581   95581    95581    95581      95581   \n",
       "gp-montreal               1070    1070     1070     1070       1070   \n",
       "gp-quebec                 1299    1299     1299     1299       1299   \n",
       "gran-camino                792     792      792      792        792   \n",
       "il-lombardia              3069    3069     3069     3069       3069   \n",
       "itzulia-basque-country   17936   17936    17936    17936      17936   \n",
       "la-fleche-wallone         5073    5073     5073     5073       5073   \n",
       "liege-bastogne-liege      4663    4663     4663     4663       4663   \n",
       "milano-sanremo            6454    6454     6454     6454       6454   \n",
       "omloop-het-nieuwsblad     4097    4097     4097     4097       4097   \n",
       "paris-nice               32362   32362    32362    32362      32362   \n",
       "paris-roubaix             3666    3666     3666     3666       3666   \n",
       "ronde-van-vlaanderen      4444    4444     4444     4444       4444   \n",
       "san-sebastian             4506    4506     4506     4506       4506   \n",
       "strade-bianche            1265    1265     1265     1265       1265   \n",
       "tirreno-adriatico        27622   27622    27622    27622      27622   \n",
       "tour-de-france          145483  145483   145483   145483     145483   \n",
       "tour-de-romandie         20294   20294    20294    20294      20294   \n",
       "tour-de-suisse           33679   33679    33679    33679      33679   \n",
       "uae-tour                  4102    4102     4102     4102       4102   \n",
       "volta-a-catalunya        26022   26022    26022    26022      26022   \n",
       "vuelta-a-espana         105382  105382   105382   105382     105382   \n",
       "world-championship        3917    3917     3917     3917       3917   \n",
       "\n",
       "                        difficulty_level  points  length  climb_total  \\\n",
       "std_name                                                                \n",
       "amstel-gold-race                    4349    4349    4349         4349   \n",
       "dauphine                           26669   26669   26669        26669   \n",
       "dwars-door-vlaanderen               2656    2656    2656         2656   \n",
       "e3-harelbeke                        3287    3287    3287         3287   \n",
       "giro-d-italia                      95581   95581   95581        95581   \n",
       "gp-montreal                         1070    1070    1070         1070   \n",
       "gp-quebec                           1299    1299    1299         1299   \n",
       "gran-camino                          792     792     792          792   \n",
       "il-lombardia                        3069    3069    3069         3069   \n",
       "itzulia-basque-country             17936   17936   17936        17936   \n",
       "la-fleche-wallone                   5073    5073    5073         5073   \n",
       "liege-bastogne-liege                4663    4663    4663         4663   \n",
       "milano-sanremo                      6454    6454    6454         6454   \n",
       "omloop-het-nieuwsblad               4097    4097    4097         4097   \n",
       "paris-nice                         32362   32362   32362        32362   \n",
       "paris-roubaix                       3666    3666    3666         3666   \n",
       "ronde-van-vlaanderen                4444    4444    4444         4444   \n",
       "san-sebastian                       4506    4506    4506         4506   \n",
       "strade-bianche                      1265    1265    1265         1265   \n",
       "tirreno-adriatico                  27622   27622   27622        27622   \n",
       "tour-de-france                    145483  145483  145483       145483   \n",
       "tour-de-romandie                   20294   20294   20294        20294   \n",
       "tour-de-suisse                     33679   33679   33679        33679   \n",
       "uae-tour                            4102    4102    4102         4102   \n",
       "volta-a-catalunya                  26022   26022   26022        26022   \n",
       "vuelta-a-espana                   105382  105382  105382       105382   \n",
       "world-championship                  3917    3917    3917         3917   \n",
       "\n",
       "                        competitive_age  startlist_quality   delta  \\\n",
       "std_name                                                             \n",
       "amstel-gold-race                   4349               4349    4349   \n",
       "dauphine                          26669              26669   26669   \n",
       "dwars-door-vlaanderen              2656               2656    2656   \n",
       "e3-harelbeke                       3287               3287    3287   \n",
       "giro-d-italia                     95581              95581   95581   \n",
       "gp-montreal                        1070               1070    1070   \n",
       "gp-quebec                          1299               1299    1299   \n",
       "gran-camino                         792                792     792   \n",
       "il-lombardia                       3069               3069    3069   \n",
       "itzulia-basque-country            17936              17936   17936   \n",
       "la-fleche-wallone                  5073               5073    5073   \n",
       "liege-bastogne-liege               4663               4663    4663   \n",
       "milano-sanremo                     6454               6454    6454   \n",
       "omloop-het-nieuwsblad              4097               4097    4097   \n",
       "paris-nice                        32362              32362   32362   \n",
       "paris-roubaix                      3666               3666    3666   \n",
       "ronde-van-vlaanderen               4444               4444    4444   \n",
       "san-sebastian                      4506               4506    4506   \n",
       "strade-bianche                     1265               1265    1265   \n",
       "tirreno-adriatico                 27622              27622   27622   \n",
       "tour-de-france                   145483             145483  145483   \n",
       "tour-de-romandie                  20294              20294   20294   \n",
       "tour-de-suisse                    33679              33679   33679   \n",
       "uae-tour                           4102               4102    4102   \n",
       "volta-a-catalunya                 26022              26022   26022   \n",
       "vuelta-a-espana                  105382             105382  105382   \n",
       "world-championship                 3917               3917    3917   \n",
       "\n",
       "                        performance_index  difficulty  convenience_score  \\\n",
       "std_name                                                                   \n",
       "amstel-gold-race                     4349        4349               4349   \n",
       "dauphine                            26669       26669              26669   \n",
       "dwars-door-vlaanderen                2656        2656               2656   \n",
       "e3-harelbeke                         3287        3287               3287   \n",
       "giro-d-italia                       95581       95581              95581   \n",
       "gp-montreal                          1070        1070               1070   \n",
       "gp-quebec                            1299        1299               1299   \n",
       "gran-camino                           792         792                792   \n",
       "il-lombardia                         3069        3069               3069   \n",
       "itzulia-basque-country              17936       17936              17936   \n",
       "la-fleche-wallone                    5073        5073               5073   \n",
       "liege-bastogne-liege                 4663        4663               4663   \n",
       "milano-sanremo                       6454        6454               6454   \n",
       "omloop-het-nieuwsblad                4097        4097               4097   \n",
       "paris-nice                          32362       32362              32362   \n",
       "paris-roubaix                        3666        3666               3666   \n",
       "ronde-van-vlaanderen                 4444        4444               4444   \n",
       "san-sebastian                        4506        4506               4506   \n",
       "strade-bianche                       1265        1265               1265   \n",
       "tirreno-adriatico                   27622       27622              27622   \n",
       "tour-de-france                     145483      145483             145483   \n",
       "tour-de-romandie                    20294       20294              20294   \n",
       "tour-de-suisse                      33679       33679              33679   \n",
       "uae-tour                             4102        4102               4102   \n",
       "volta-a-catalunya                   26022       26022              26022   \n",
       "vuelta-a-espana                    105382      105382             105382   \n",
       "world-championship                   3917        3917               3917   \n",
       "\n",
       "                        difficulty_score  gain_ratio  cyclist_age  position  \\\n",
       "std_name                                                                      \n",
       "amstel-gold-race                    4349        4349         4349      4349   \n",
       "dauphine                           26669       26669        26669     26669   \n",
       "dwars-door-vlaanderen               2656        2656         2656      2656   \n",
       "e3-harelbeke                        3287        3287         3287      3287   \n",
       "giro-d-italia                      95581       95581        95581     95581   \n",
       "gp-montreal                         1070        1070         1070      1070   \n",
       "gp-quebec                           1299        1299         1299      1299   \n",
       "gran-camino                          792         792          792       792   \n",
       "il-lombardia                        3069        3069         3069      3069   \n",
       "itzulia-basque-country             17936       17936        17936     17936   \n",
       "la-fleche-wallone                   5073        5073         5073      5073   \n",
       "liege-bastogne-liege                4663        4663         4663      4663   \n",
       "milano-sanremo                      6454        6454         6454      6454   \n",
       "omloop-het-nieuwsblad               4097        4097         4097      4097   \n",
       "paris-nice                         32362       32362        32362     32362   \n",
       "paris-roubaix                       3666        3666         3666      3666   \n",
       "ronde-van-vlaanderen                4444        4444         4444      4444   \n",
       "san-sebastian                       4506        4506         4506      4506   \n",
       "strade-bianche                      1265        1265         1265      1265   \n",
       "tirreno-adriatico                  27622       27622        27622     27622   \n",
       "tour-de-france                    145483      145483       145483    145483   \n",
       "tour-de-romandie                   20294       20294        20294     20294   \n",
       "tour-de-suisse                     33679       33679        33679     33679   \n",
       "uae-tour                            4102        4102         4102      4102   \n",
       "volta-a-catalunya                  26022       26022        26022     26022   \n",
       "vuelta-a-espana                   105382      105382       105382    105382   \n",
       "world-championship                  3917        3917         3917      3917   \n",
       "\n",
       "                        cyclist_team  \n",
       "std_name                              \n",
       "amstel-gold-race                4349  \n",
       "dauphine                       26669  \n",
       "dwars-door-vlaanderen           2656  \n",
       "e3-harelbeke                    3287  \n",
       "giro-d-italia                  95581  \n",
       "gp-montreal                     1070  \n",
       "gp-quebec                       1299  \n",
       "gran-camino                      792  \n",
       "il-lombardia                    3069  \n",
       "itzulia-basque-country         17936  \n",
       "la-fleche-wallone               5073  \n",
       "liege-bastogne-liege            4663  \n",
       "milano-sanremo                  6454  \n",
       "omloop-het-nieuwsblad           4097  \n",
       "paris-nice                     32362  \n",
       "paris-roubaix                   3666  \n",
       "ronde-van-vlaanderen            4444  \n",
       "san-sebastian                   4506  \n",
       "strade-bianche                  1265  \n",
       "tirreno-adriatico              27622  \n",
       "tour-de-france                145483  \n",
       "tour-de-romandie               20294  \n",
       "tour-de-suisse                 33679  \n",
       "uae-tour                        4102  \n",
       "volta-a-catalunya              26022  \n",
       "vuelta-a-espana               105382  \n",
       "world-championship              3917  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.cluster import DBSCAN\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "RACES_PATH=path.join(\"..\",\"dataset\",\"engineered_races.csv\")\n",
    "races_df=pd.read_csv(RACES_PATH)\n",
    "def most_frequent(series):\n",
    "    return series.mode()[0] if not series.mode().empty else series.iloc[0]\n",
    "\n",
    "clustering_data=races_df.groupby(['date','stage','std_name','cyclist']).agg({\n",
    "    'profile':most_frequent,\n",
    "    'is_tarmac':most_frequent,\n",
    "    'difficulty_level':most_frequent,\n",
    "\n",
    "    'points':'sum',\n",
    "\n",
    "    'length':'mean',\n",
    "    'climb_total':'mean',\n",
    "    'competitive_age':'mean',\n",
    "    'startlist_quality':'mean',\n",
    "    'delta':'mean',\n",
    "    'performance_index':'mean',\n",
    "    'difficulty':'mean',\n",
    "    'convenience_score':'mean',\n",
    "    'difficulty_score':'mean',\n",
    "    'gain_ratio':'mean',\n",
    "\n",
    "    'cyclist_age':'first',\n",
    "    'position':'first',\n",
    "    'cyclist_team':'first',\n",
    "}).reset_index()\n",
    "clustering_data.groupby('std_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amstel-gold-race': 1108, 'dauphine': 6671, 'dwars-door-vlaanderen': 648, 'e3-harelbeke': 821, 'giro-d-italia': 23911, 'gp-montreal': 269, 'gp-quebec': 327, 'gran-camino': 175, 'il-lombardia': 749, 'itzulia-basque-country': 4528, 'la-fleche-wallone': 1271, 'liege-bastogne-liege': 1190, 'milano-sanremo': 1638, 'omloop-het-nieuwsblad': 1005, 'paris-nice': 8011, 'paris-roubaix': 909, 'ronde-van-vlaanderen': 1076, 'san-sebastian': 1168, 'strade-bianche': 304, 'tirreno-adriatico': 6844, 'tour-de-france': 36613, 'tour-de-romandie': 4985, 'tour-de-suisse': 8383, 'uae-tour': 1072, 'volta-a-catalunya': 6528, 'vuelta-a-espana': 26282, 'world-championship': 949}\n",
      "\n",
      "number of groups=27\n",
      "initial eps values per group={'amstel-gold-race': 1.331096502661081, 'dauphine': 0.8401145858418447, 'dwars-door-vlaanderen': 1.2632881010334707, 'e3-harelbeke': 1.3823696824421974, 'giro-d-italia': 0.7261308576322284, 'gp-montreal': 2.0184520099061922, 'gp-quebec': 1.882460185176687, 'gran-camino': 2.48516596897522, 'il-lombardia': 1.5506727846549828, 'itzulia-basque-country': 0.8452659110799418, 'la-fleche-wallone': 1.218109739079851, 'liege-bastogne-liege': 1.1503698549166639, 'milano-sanremo': 1.1791286929175373, 'omloop-het-nieuwsblad': 1.3929146609995655, 'paris-nice': 0.7159588646456468, 'paris-roubaix': 1.3358499882145012, 'ronde-van-vlaanderen': 1.5309397350047724, 'san-sebastian': 1.181046870316286, 'strade-bianche': 2.273745198003877, 'tirreno-adriatico': 0.7594376499420227, 'tour-de-france': 0.7022492063016823, 'tour-de-romandie': 0.874099873810812, 'tour-de-suisse': 0.7790385407584299, 'uae-tour': 1.2189248750102053, 'volta-a-catalunya': 0.8138912732829563, 'vuelta-a-espana': 0.7271848730480671, 'world-championship': 1.5413624580363428}\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ohe_diff_lvl=pd.get_dummies(races_df['difficulty_level']).astype(float)\n",
    "clustering_data[ohe_diff_lvl.columns]=ohe_diff_lvl\n",
    "\n",
    "ohe_tarmac=pd.get_dummies(races_df['is_tarmac']).astype(float)\n",
    "\n",
    "cols=list(ohe_tarmac.columns)\n",
    "cols[0]='True_is_tarmac'\n",
    "cols[1]='False_is_tarmac'\n",
    "clustering_data[cols]=ohe_tarmac\n",
    "\n",
    "\n",
    "clustering_data=clustering_data.drop(columns=[\"cyclist\",\"cyclist_team\",\"is_tarmac\",\"difficulty_level\",\"date\",\"stage\"]).drop_duplicates()\n",
    "\n",
    "std_scaler=StandardScaler()\n",
    "\n",
    "clustering_data=utils.random_sampling_reduce(clustering_data,0.25)\n",
    "\n",
    "races_groups=clustering_data.groupby('std_name')\n",
    "normalized_races_groups={k:std_scaler.fit_transform(g.drop(columns=\"std_name\").drop_duplicates()) for k,g in races_groups }\n",
    "\n",
    "print({k:len(g) for k,g in normalized_races_groups.items()})\n",
    "\n",
    "initial_eps=dict()\n",
    "\n",
    "kth_neighbor=4\n",
    "\n",
    "for k,data in normalized_races_groups.items():\n",
    "    min_pts=data.shape[1]\n",
    "    nn=NearestNeighbors(n_neighbors=min_pts-1,n_jobs=-1)\n",
    "    nn.fit(data)\n",
    "    distances,indices= nn.kneighbors(data)\n",
    "    k_distances= np.sort(distances[:, -1])\n",
    "\n",
    "    initial_eps[k]=k_distances[kth_neighbor-1]\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "number of groups={len(normalized_races_groups)}\n",
    "initial eps values per group={initial_eps}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    period amstel-gold-race\n",
      "    maxium distance: 13.372756617282896\n",
      "    average concentration:82.85501873024634\n",
      "    eps values:[6.65548251e+02 3.32774126e+02 1.33109650e+02 6.65548251e+01\n",
      " 1.33109650e+01 6.65548251e+00 3.32774126e+00 1.33109650e+00\n",
      " 1.33109650e-01 1.33109650e-02 1.33109650e-04]\n",
      "    used metrics:['euclidean']\n",
      "    number of minimum samples:1107\n",
      "    number of samples used:1108\n",
      "    \n",
      "-0 - (665.5482513305406, 'euclidean', 1107)\n",
      "dbscan done, time=0.02056097984313965 seconds | silhoutte score:all noise\n",
      "-1 - (332.7741256652703, 'euclidean', 1107)\n",
      "dbscan done, time=0.016307830810546875 seconds | silhoutte score:all noise\n",
      "-2 - (133.1096502661081, 'euclidean', 1107)\n",
      "dbscan done, time=0.02366805076599121 seconds | silhoutte score:all noise\n",
      "-3 - (66.55482513305405, 'euclidean', 1107)\n",
      "dbscan done, time=0.019884347915649414 seconds | silhoutte score:all noise\n",
      "-4 - (13.31096502661081, 'euclidean', 1107)\n",
      "dbscan done, time=0.01560664176940918 seconds | silhoutte score:all noise\n",
      "-5 - (6.655482513305405, 'euclidean', 1107)\n",
      "dbscan done, time=0.01606607437133789 seconds | silhoutte score:all noise\n",
      "-6 - (3.3277412566527027, 'euclidean', 1107)\n",
      "dbscan done, time=0.016593217849731445 seconds | silhoutte score:all noise\n",
      "-7 - (1.331096502661081, 'euclidean', 1107)\n",
      "dbscan done, time=0.01572871208190918 seconds | silhoutte score:all noise\n",
      "-8 - (0.1331096502661081, 'euclidean', 1107)\n",
      "dbscan done, time=0.012217521667480469 seconds | silhoutte score:all noise\n",
      "-9 - (0.01331096502661081, 'euclidean', 1107)\n",
      "dbscan done, time=0.013625621795654297 seconds | silhoutte score:all noise\n",
      "-10 - (0.00013310965026610812, 'euclidean', 1107)\n",
      "dbscan done, time=0.014653682708740234 seconds | silhoutte score:all noise\n",
      "\n",
      "    period dauphine\n",
      "    maxium distance: 46.437519185629036\n",
      "    average concentration:143.6553915236813\n",
      "    eps values:[4.20057293e+02 2.10028646e+02 8.40114586e+01 4.20057293e+01\n",
      " 8.40114586e+00 4.20057293e+00 2.10028646e+00 8.40114586e-01\n",
      " 8.40114586e-02 8.40114586e-03 8.40114586e-05]\n",
      "    used metrics:['euclidean']\n",
      "    number of minimum samples:6670\n",
      "    number of samples used:6671\n",
      "    \n",
      "-0 - (420.05729292092235, 'euclidean', 6670)\n",
      "dbscan done, time=0.8577680587768555 seconds | silhoutte score:all noise\n",
      "-1 - (210.02864646046118, 'euclidean', 6670)\n",
      "dbscan done, time=0.7839016914367676 seconds | silhoutte score:all noise\n",
      "-2 - (84.01145858418447, 'euclidean', 6670)\n",
      "dbscan done, time=0.8659484386444092 seconds | silhoutte score:all noise\n",
      "-3 - (42.005729292092234, 'euclidean', 6670)\n",
      "dbscan done, time=0.8040776252746582 seconds | silhoutte score:all noise\n",
      "-4 - (8.401145858418447, 'euclidean', 6670)\n",
      "dbscan done, time=0.7542896270751953 seconds | silhoutte score:all noise\n",
      "-5 - (4.2005729292092235, 'euclidean', 6670)\n",
      "dbscan done, time=0.7563626766204834 seconds | silhoutte score:all noise\n",
      "-6 - (2.1002864646046118, 'euclidean', 6670)\n",
      "dbscan done, time=0.7305552959442139 seconds | silhoutte score:all noise\n",
      "-7 - (0.8401145858418447, 'euclidean', 6670)\n",
      "dbscan done, time=0.5919501781463623 seconds | silhoutte score:all noise\n",
      "-8 - (0.08401145858418448, 'euclidean', 6670)\n",
      "dbscan done, time=0.6321020126342773 seconds | silhoutte score:all noise\n",
      "-9 - (0.008401145858418448, 'euclidean', 6670)\n",
      "dbscan done, time=0.5802090167999268 seconds | silhoutte score:all noise\n",
      "-10 - (8.401145858418448e-05, 'euclidean', 6670)\n",
      "dbscan done, time=0.5828545093536377 seconds | silhoutte score:all noise\n",
      "\n",
      "    period dwars-door-vlaanderen\n",
      "    maxium distance: 20.052719866897046\n",
      "    average concentration:32.31481835387906\n",
      "    eps values:[6.31644051e+02 3.15822025e+02 1.26328810e+02 6.31644051e+01\n",
      " 1.26328810e+01 6.31644051e+00 3.15822025e+00 1.26328810e+00\n",
      " 1.26328810e-01 1.26328810e-02 1.26328810e-04]\n",
      "    used metrics:['euclidean']\n",
      "    number of minimum samples:647\n",
      "    number of samples used:648\n",
      "    \n",
      "-0 - (631.6440505167353, 'euclidean', 647)\n",
      "dbscan done, time=0.006767988204956055 seconds | silhoutte score:all noise\n",
      "-1 - (315.82202525836766, 'euclidean', 647)\n",
      "dbscan done, time=0.005177497863769531 seconds | silhoutte score:all noise\n",
      "-2 - (126.32881010334707, 'euclidean', 647)\n",
      "dbscan done, time=0.005352020263671875 seconds | silhoutte score:all noise\n",
      "-3 - (63.16440505167353, 'euclidean', 647)\n",
      "dbscan done, time=0.005344390869140625 seconds | silhoutte score:all noise\n",
      "-4 - (12.632881010334707, 'euclidean', 647)\n",
      "dbscan done, time=0.005298137664794922 seconds | silhoutte score:all noise\n",
      "-5 - (6.316440505167353, 'euclidean', 647)\n",
      "dbscan done, time=0.006379127502441406 seconds | silhoutte score:all noise\n",
      "-6 - (3.1582202525836767, 'euclidean', 647)\n",
      "dbscan done, time=0.0053136348724365234 seconds | silhoutte score:all noise\n",
      "-7 - (1.2632881010334707, 'euclidean', 647)\n",
      "dbscan done, time=0.005213022232055664 seconds | silhoutte score:all noise\n",
      "-8 - (0.12632881010334707, 'euclidean', 647)\n",
      "dbscan done, time=0.004124164581298828 seconds | silhoutte score:all noise\n",
      "-9 - (0.012632881010334707, 'euclidean', 647)\n",
      "dbscan done, time=0.0041751861572265625 seconds | silhoutte score:all noise\n",
      "-10 - (0.00012632881010334708, 'euclidean', 647)\n",
      "dbscan done, time=0.0037605762481689453 seconds | silhoutte score:all noise\n",
      "\n",
      "    period e3-harelbeke\n",
      "    maxium distance: 21.161385938042365\n",
      "    average concentration:38.79708079630396\n",
      "    eps values:[6.91184841e+02 3.45592421e+02 1.38236968e+02 6.91184841e+01\n",
      " 1.38236968e+01 6.91184841e+00 3.45592421e+00 1.38236968e+00\n",
      " 1.38236968e-01 1.38236968e-02 1.38236968e-04]\n",
      "    used metrics:['euclidean']\n",
      "    number of minimum samples:820\n",
      "    number of samples used:821\n",
      "    \n",
      "-0 - (691.1848412210987, 'euclidean', 820)\n",
      "dbscan done, time=0.009250402450561523 seconds | silhoutte score:all noise\n",
      "-1 - (345.59242061054937, 'euclidean', 820)\n",
      "dbscan done, time=0.008983850479125977 seconds | silhoutte score:all noise\n",
      "-2 - (138.23696824421972, 'euclidean', 820)\n",
      "dbscan done, time=0.01003122329711914 seconds | silhoutte score:all noise\n",
      "-3 - (69.11848412210986, 'euclidean', 820)\n",
      "dbscan done, time=0.00903630256652832 seconds | silhoutte score:all noise\n",
      "-4 - (13.823696824421974, 'euclidean', 820)\n",
      "dbscan done, time=0.010093927383422852 seconds | silhoutte score:all noise\n",
      "-5 - (6.911848412210987, 'euclidean', 820)\n",
      "dbscan done, time=0.008789777755737305 seconds | silhoutte score:all noise\n",
      "-6 - (3.4559242061054936, 'euclidean', 820)\n",
      "dbscan done, time=0.008635282516479492 seconds | silhoutte score:all noise\n",
      "-7 - (1.3823696824421974, 'euclidean', 820)\n",
      "dbscan done, time=0.008615255355834961 seconds | silhoutte score:all noise\n",
      "-8 - (0.13823696824421974, 'euclidean', 820)\n",
      "dbscan done, time=0.0071604251861572266 seconds | silhoutte score:all noise\n",
      "-9 - (0.013823696824421973, 'euclidean', 820)\n",
      "dbscan done, time=0.00793004035949707 seconds | silhoutte score:all noise\n",
      "-10 - (0.00013823696824421974, 'euclidean', 820)\n",
      "dbscan done, time=0.007254838943481445 seconds | silhoutte score:all noise\n",
      "\n",
      "    period giro-d-italia\n",
      "    maxium distance: 40.67297289538593\n",
      "    average concentration:587.8842459217565\n",
      "    eps values:[3.63065429e+02 1.81532714e+02 7.26130858e+01 3.63065429e+01\n",
      " 7.26130858e+00 3.63065429e+00 1.81532714e+00 7.26130858e-01\n",
      " 7.26130858e-02 7.26130858e-03 7.26130858e-05]\n",
      "    used metrics:['euclidean']\n",
      "    number of minimum samples:23910\n",
      "    number of samples used:23911\n",
      "    \n",
      "-0 - (363.0654288161142, 'euclidean', 23910)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "group_results=pd.DataFrame()\n",
    "for k,decade_data in normalized_races_groups.items():\n",
    "    #NOTE: this might have to be revisited for it's just to try if everyting works\n",
    "    dimension=decade_data.shape[0]\n",
    "    min_pts=int(dimension-1)\n",
    "    #using the method seen at laboratory to select initial values\n",
    "    #print(decade_data.drop(columns=\"decade\").info())\n",
    "    maximum_distance = abs(decade_data.max() - decade_data.min()).sum().item()\n",
    "    average_concentration = dimension / maximum_distance\n",
    "    #use diferent scales for eps values\n",
    "    # during the tests a lot of low values where not taken into consideration\n",
    "    eps_values=initial_eps[k] * np.array([500,250,100,50,10, 5, 2.5, 1, 0.1, 0.01, 0.0001])\n",
    "    #try various metrics\n",
    "    metrics=['euclidean']\n",
    "\n",
    "    min_pts_values=[min_pts]\n",
    "    print(\n",
    "    f\"\"\"\n",
    "    period {k}\n",
    "    maxium distance: {maximum_distance}\n",
    "    average concentration:{average_concentration}\n",
    "    eps values:{eps_values}\n",
    "    used metrics:{metrics}\n",
    "    number of minimum samples:{min_pts}\n",
    "    number of samples used:{decade_data.shape[0]}\n",
    "    \"\"\"\n",
    "    )\n",
    "    gc.collect()\n",
    "    #normalization is done for each group\n",
    "    result=utils.run_dbscan(min_pts_values,eps_values,metrics,decade_data)\n",
    "    result[\"group\"]=k\n",
    "    group_results=pd.concat([group_results,result])\n",
    "group_results.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
