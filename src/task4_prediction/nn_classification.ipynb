{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task no. 4\n",
    "\n",
    "This is the notebook taking care of the task no.4 : feature prediction.\n",
    "\n",
    "In our analysis we have decided very different models to see how they differ from eachother in term of performance and also their explainability to see if they make sense.\n",
    "\n",
    "For this notebook we decided to explore the nature of NeuralNetworks on the dataset.\n",
    "\n",
    "First a preparation is due to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "RACES_PATH=os.path.join(\"..\",\"dataset\",\"engineered_races.csv\")\n",
    "\n",
    "races_df=pd.read_csv(RACES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we binarize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "races_df['position']=(races_df['position']>20).astype(int)\n",
    "races_df['date']=pd.to_datetime(races_df['date'])\n",
    "\n",
    "\n",
    "split_idx= races_df['date'].dt.year <= 2022\n",
    "\n",
    "X_test_set=races_df.loc[~split_idx].drop(columns='position')\n",
    "\n",
    "X_dev_set=races_df[split_idx].drop(columns='position')\n",
    "Y_dev_set=races_df.loc[split_idx,'position']\n",
    "\n",
    "X_train_set,X_val_set,Y_train_set,Y_val_set=train_test_split(\n",
    "    X_dev_set,\n",
    "    Y_dev_set,\n",
    "    test_size=0.2,\n",
    "    stratify=Y_dev_set,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first a stratification can only help the generization capabilities.\n",
    "\n",
    "Now we have to setup the task, for this kind of setting the binary cross entropy is the most appropriate given we just want to classify stuff and we are not doing any regression whatsoever.\n",
    "\n",
    "A first test using a simple NN might be usefull in this case to see the most basic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "\n",
    "initializer=initializers.HeNormal()\n",
    "\n",
    "input_size=train_set.shape[1]\n",
    "\n",
    "output_size=1\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', \n",
    "                 kernel_initializer=initializer,  # He initialization\n",
    "                 bias_initializer=initializer,       # Bias initialized to zeros\n",
    "                 input_shape=(input_size,)),                          # Input shape\n",
    "    layers.Dense(32, activation='relu',\n",
    "                 kernel_initializer=initializer),  # Xavier initialization\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy','f1-score']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_set,Y_train_set,\n",
    "    epochs=100\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
